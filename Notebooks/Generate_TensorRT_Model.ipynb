{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e19d014",
   "metadata": {},
   "source": [
    "Check Numeric Overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb97be-93a7-4c96-a81d-4359b39dc6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "import numpy as np\n",
    "\n",
    "def is_overflow_in_fp16(tensor):\n",
    "    original_data = np.asarray(tensor, dtype=np.float32)\n",
    "    fp16_data = original_data.astype(np.float16)\n",
    "    back_converted_data = fp16_data.astype(np.float32)\n",
    "\n",
    "    diff = np.abs(back_converted_data - original_data)\n",
    "    return np.any(diff > 0.001)\n",
    "\n",
    "def is_truncated_in_fp16(tensor):\n",
    "    original_data = np.asarray(tensor, dtype=np.float32)\n",
    "\n",
    "    return np.any(np.abs(original_data) <= 0.0000001)  # Check if the FP16 weight is zero\n",
    "\n",
    "\n",
    "model = onnx.load(\"AsymFormer.onnx\")  # Load ONNX model\n",
    "overflow_list=[]\n",
    "for node in model.graph.node:\n",
    "    if node.input:  # Check network layer which has 'input'\n",
    "        for input_name in node.input:\n",
    "            weight = next((init for init in model.graph.initializer if init.name == input_name), None)\n",
    "            if weight is not None:  # Make sure the layer has 'weight'\n",
    "                weights = onnx.numpy_helper.to_array(weight)\n",
    "                if is_overflow_in_fp16(weights):\n",
    "                    print(f\"Node {node.name} ({node.op_type}): Weight overflow in fp16\")\n",
    "                    overflow_list.append(node.name)\n",
    "                if is_truncated_in_fp16(weights):\n",
    "                    print(f\"Node {node.name} ({node.op_type}): Weight truncated in fp16\")\n",
    "                    overflow_list.append(node.name)\n",
    "\n",
    "print('个数：',len(overflow_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f1449f",
   "metadata": {},
   "source": [
    "Generate Mixed Precision TensorRT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4243ef42-0eb7-4385-9140-70328317deee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorrt as trt\n",
    "\n",
    "def build_engine(onnx_file_path, engine_file_path, overflow_list, flop=16):\n",
    "    trt_logger = trt.Logger(trt.Logger.WARNING)  # trt.Logger.ERROR\n",
    "    builder = trt.Builder(trt_logger)\n",
    "    builder_config = builder.create_builder_config()\n",
    "    \n",
    "    network = builder.create_network(\n",
    "        1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "    )\n",
    "    \n",
    "    parser = trt.OnnxParser(network, trt_logger)\n",
    "    # parse ONNX\n",
    "    with open(onnx_file_path, 'rb') as model:\n",
    "        if not parser.parse(model.read()):\n",
    "            print('ERROR: Failed to parse the ONNX file.')\n",
    "            for error in range(parser.num_errors):\n",
    "                print(parser.get_error(error))\n",
    "            return None\n",
    "    print(\"Completed parsing ONNX file\")\n",
    "\n",
    "    # default = 1 for fixed batch size\n",
    "    builder.max_batch_size = 1\n",
    "    # set mixed flop computation for the best performance\n",
    "    \n",
    "    builder_config.set_flag(trt.BuilderFlag.FP16)\n",
    "\n",
    "    if os.path.isfile(engine_file_path):\n",
    "        try:\n",
    "            os.remove(engine_file_path)\n",
    "        except Exception:\n",
    "            print(\"Cannot remove existing file: \",\n",
    "                engine_file_path)\n",
    "\n",
    "    print(\"Creating Tensorrt Engine\")\n",
    "\n",
    "    for layer in network:\n",
    "        for layer_name in overflow_list:\n",
    "            if layer_name in layer.name:\n",
    "                layer.precision = trt.float32\n",
    "                print(f'Network Layer: {layer.name}, {layer.type}, {layer.precision}, is_set: {layer.precision_is_set}')\n",
    "\n",
    "    config = builder.create_builder_config()\n",
    "    config.set_tactic_sources(1 << int(trt.TacticSource.CUBLAS))\n",
    "    config.max_workspace_size = 2 << 30\n",
    "    config.set_flag(trt.BuilderFlag.FP16)\n",
    "    config.set_flag(trt.BuilderFlag.STRICT_TYPES)\n",
    "\n",
    "    print('config.flags: ', config.flags)\n",
    "    \n",
    "    engine = builder.build_engine(network, config)\n",
    "    with open(engine_file_path, \"wb\") as f:\n",
    "        f.write(engine.serialize())\n",
    "    print(\"Serialized Engine Saved at: \", engine_file_path)\n",
    "    return engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750a6718-2daa-448a-9a89-922438199aea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ONNX_SIM_MODEL_PATH = 'AsymFormer.onnx'\n",
    "TENSORRT_ENGINE_PATH_PY = 'AsymFormer.engine'\n",
    "\n",
    "build_engine(ONNX_SIM_MODEL_PATH, TENSORRT_ENGINE_PATH_PY, overflow_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588f4ac3-1502-4cf4-8e4e-399f19a6535c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
